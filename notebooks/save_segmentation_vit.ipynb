{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bda3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import skimage.color as sk_color\n",
    "import skimage.morphology as sk_morph\n",
    "import scipy.io\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "sys.path.append('../moco-v3/')\n",
    "import suppix_utils.datasets_seeds as datasets\n",
    "\n",
    "sys.path.append('../vits_vis_utils/')\n",
    "import vits_vis_attn\n",
    "import segsort\n",
    "from clustering import SphericalKMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b2e17f",
   "metadata": {},
   "source": [
    "### Define models and load pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e279f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_CLASS_NAME = \"vit_base\"\n",
    "CHECKPOINT_PATH = '../ckpt/cast_base.pth.tar'\n",
    "\n",
    "model = vits_vis_attn.__dict__[MODEL_CLASS_NAME]().cuda()\n",
    "model = nn.DataParallel(model)\n",
    "# ckpt = torch.load(CHECKPOINT_PATH, map_location='cuda:0')\n",
    "# model.load_state_dict(ckpt['state_dict'], strict=True)\n",
    "model = model.module\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62f3b26",
   "metadata": {},
   "source": [
    "### Prepare dataloader for loading ImageNet images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373ceba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_ROOT = '../data/PartImageNet/images/val/'\n",
    "DATA_ROOT = './demo_images'\n",
    "SAVE_ROOT = '../pred_segs/'\n",
    "\n",
    "class ReturnIndexDataset(datasets.ImageFolder):\n",
    "    def __getitem__(self, idx):\n",
    "        img, seg, lab = super(ReturnIndexDataset, self).__getitem__(idx)\n",
    "        return img, seg, lab, idx\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225])\n",
    "\n",
    "augmentation = [\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "]\n",
    "\n",
    "train_dataset = ReturnIndexDataset(\n",
    "    DATA_ROOT,\n",
    "    transforms.Compose(augmentation),\n",
    "    normalize=normalize,\n",
    "    n_segments=196,\n",
    "    compactness=10.0,\n",
    "    blur_ops=None,\n",
    "    scale_factor=1.0)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa9c2ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, (img, suppixel, label, img_inds) in enumerate(train_loader):\n",
    "    img = img.cuda() # input images\n",
    "\n",
    "    # Forward pass to return token features\n",
    "    x = model.forward_token_features(img)\n",
    "\n",
    "    # Rescale token features back to image resolution\n",
    "    x = x.unflatten(1, (14, 14)).permute(0, 3, 1, 2)\n",
    "    x = F.interpolate(x, scale_factor=(16, 16), mode='bilinear')\n",
    "    x = x.permute(0, 2, 3, 1).flatten(1, 2)\n",
    "\n",
    "    # Perform spherical K-Means to infer segmentations\n",
    "    norm_x = F.normalize(x, dim=-1)\n",
    "    segmentations = {}\n",
    "    num_segs = [64, 32, 16, 8] # We use the same granularities as CAST\n",
    "    # Iterate through the finest to the coarsest scales\n",
    "    for num_ind, num_seg in enumerate(num_segs):\n",
    "        # Iterate through the mini-batch\n",
    "        for b in range(img.shape[0]):\n",
    "            # Set up K-Means clustering arguments\n",
    "            kmeans = SphericalKMeans(K=num_seg, concentration=5, iterations=30)\n",
    "            if num_ind > 0:\n",
    "                # Gather coarser grouping at the current level\n",
    "                # The level-1 grouping index for each level-0 group is [1, 2, 2, 0, 1, 1, 0]\n",
    "                # The level-2 grouping index for each level-1 group is [0, 1, 0]\n",
    "                # We infer the level-2 grouping for each level-0 group as [1, 0, 0, 0, 1, 1, 0]\n",
    "\n",
    "                # To get coarser grouping, we calculate \"prototypes\"--the mean-average token features,\n",
    "                # within each finer group\n",
    "                prev_label = torch.from_numpy(segmentations[num_segs[num_ind-1]][b]).view(-1).cuda()\n",
    "                prototypes = segsort.calculate_prototypes_from_labels(x[b], prev_label)\n",
    "                # Perform K-Means clustering\n",
    "                kmeans_label, _ = kmeans(prototypes)\n",
    "                _, kmeans_label = torch.unique(kmeans_label, return_inverse=True)\n",
    "                kmeans_label = kmeans_label[prev_label]\n",
    "            else:\n",
    "                kmeans_label, _ = kmeans(x[b])\n",
    "                _, kmeans_label = torch.unique(kmeans_label, return_inverse=True)\n",
    "            label = kmeans_label.view(224, 224)\n",
    "\n",
    "            save_root = os.path.join(SAVE_ROOT, MODEL_CLASS_NAME, 'level{:d}'.format(num_ind + 1))\n",
    "            os.makedirs(save_root, exist_ok=True)\n",
    "\n",
    "            file_name = train_dataset.samples[img_inds[b]][0]\n",
    "            file_name = file_name.split('/')[-1].split('.')[0]\n",
    "            with open(os.path.join(save_root, '{}.npy'.format(file_name)), 'wb') as f:\n",
    "                np.save(f, label.cpu().data.numpy())\n",
    "\n",
    "            if num_seg not in segmentations.keys():\n",
    "                segmentations[num_seg] = []\n",
    "            segmentations[num_seg].append(kmeans_label.view(224, 224).data.cpu().numpy())\n",
    "        segmentations[num_seg] = np.stack(segmentations[num_seg], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dcb084-136d-4682-baa2-337538767f86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cast",
   "language": "python",
   "name": "cast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
